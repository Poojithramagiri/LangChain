{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPff2m78iWtpcPALQYd3+0F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bX7rdDB7Itwj","executionInfo":{"status":"ok","timestamp":1720137675203,"user_tz":300,"elapsed":41832,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"eebb21f5-5d2e-4f71-c888-1e476637e177"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install -q langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WgZxMJYzNN3w","executionInfo":{"status":"ok","timestamp":1720137917627,"user_tz":300,"elapsed":13593,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"01c28f7e-2fb0-4471-8b2c-be6cc6ecc74c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import langchain"],"metadata":{"id":"Yiv9rTj4Na_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install -q langchain-google-genai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eg3iZ8ANNp4J","executionInfo":{"status":"ok","timestamp":1720138112402,"user_tz":300,"elapsed":16276,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"f879de0f-df38-48e2-8d79-92725a2e47b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["%pip install --upgrade -q langchain-google-genai"],"metadata":{"id":"i5j0yaCUOLH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install -q google-generativeai"],"metadata":{"id":"cyl7Uuw8OY0V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import getpass\n","import os\n","if 'GOOGLE_API_KEY' not in os.environ:\n","    os.environ['GOOGLE_API_KEY'] = getpass.getpass('Provide your Google API Key:')"],"metadata":{"id":"BNMjl9E-Os5j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install -U langchain-community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYSAAxGyO-os","executionInfo":{"status":"ok","timestamp":1720138349850,"user_tz":300,"elapsed":11373,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"07e1cb35-0590-40cf-edb4-fa4ac8c15e2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-community\n","  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.6)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.11)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.83)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (0.2.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (2.8.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (24.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (2.20.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n","Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.6 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["import os\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings import OpenAIEmbeddings\n","from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n","from langchain.chains import RetrievalQA\n","#from langchain.retrievers import VectorstoreRetriever\n","from langchain.memory import ConversationBufferMemory\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.schema import SystemMessage"],"metadata":{"id":"VrnD38qRM6xM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["api_key = \"AIzaSyBCH44djBwy-dcdIT9HsI8AWrVobma-aiA\"\n","os.environ[\"GOOGLE_API_KEY\"] = api_key"],"metadata":{"id":"e44Ea0OeMgfw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install -q pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAYBgRSAQs5A","executionInfo":{"status":"ok","timestamp":1720138828263,"user_tz":300,"elapsed":7907,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"f6d445c4-4356-4638-9e2d-dec35c294ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/290.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m286.7/290.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["%pip install -q docx2txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbhQDCgbQ62y","executionInfo":{"status":"ok","timestamp":1720138986855,"user_tz":300,"elapsed":9148,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"d3917d61-3c4e-4b02-92a9-63353d15ec45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["%pip install -q wikipedia"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVdes99lReTN","executionInfo":{"status":"ok","timestamp":1720139010688,"user_tz":300,"elapsed":8524,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"4eaf84f8-5e1f-43c4-80ee-ac8234c44abb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["## **Loading Documents**"],"metadata":{"id":"0ccd8kFORsOW"}},{"cell_type":"code","source":["# loading PDF, DOCX and TXT files as LangChain Documents\n","def load_document(file):\n","    import os\n","    name, extension = os.path.splitext(file)\n","\n","    if extension == '.pdf':\n","        from langchain.document_loaders import PyPDFLoader\n","        print(f'Loading {file}')\n","        loader = PyPDFLoader(file)\n","    elif extension == '.docx':\n","        from langchain.document_loaders import Docx2txtLoader\n","        print(f'Loading {file}')\n","        loader = Docx2txtLoader(file)\n","    elif extension == '.txt':\n","        from langchain.document_loaders import TextLoader\n","        loader = TextLoader(file)\n","    else:\n","        print('Document format is not supported!')\n","        return None\n","\n","    data = loader.load()\n","    return data\n","\n","\n","# wikipedia\n","def load_from_wikipedia(query, lang='en', load_max_docs=2):\n","    from langchain.document_loaders import WikipediaLoader\n","    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n","    data = loader.load()\n","    return data"],"metadata":{"id":"xzqPodmsRknF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Chunking Data**"],"metadata":{"id":"1Ccd0VJvSBRS"}},{"cell_type":"code","source":["def chunk_data(data, chunk_size=256):\n","    from langchain.text_splitter import RecursiveCharacterTextSplitter\n","    from langchain.schema import Document\n","\n","    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n","    chunks = text_splitter.split_documents(data)\n","\n","    # Ensure chunks are in the correct format (list of Document objects with page_content as string)\n","    chunk_docs = [Document(page_content=chunk['page_content'], metadata=chunk['metadata']) for chunk in chunks]\n","\n","    return chunk_docs\n"],"metadata":{"id":"TL8tIbrgSO2k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Asking and Getting Answers**"],"metadata":{"id":"PCohIIgQSUWy"}},{"cell_type":"code","source":["def ask_and_get_answer(vector_store, q, k=3):\n","    from langchain.chains import RetrievalQA\n","    from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","    llm = ChatGoogleGenerativeAI(\n","    api_key=api_key,\n","    model=\"gemini-1.0-pro\",\n","    temperature=0.9\n",")\n","\n","    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n","\n","    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n","\n","    answer = chain.invoke(q)\n","    return answer"],"metadata":{"id":"R7IuagjPSs7t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Chroma as Vector DB**"],"metadata":{"id":"OEctDAI-Td4M"}},{"cell_type":"code","source":["%pip install -q chromadb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taSxGUAfTjAd","executionInfo":{"status":"ok","timestamp":1720139577820,"user_tz":300,"elapsed":32465,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"09516e23-6c6f-46c9-ce0a-aadfc6afed9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["%pip install chromadb sentence-transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PhaH1nkWEbO","executionInfo":{"status":"ok","timestamp":1720140309178,"user_tz":300,"elapsed":101644,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"8ebea5c1-3382-4941-e691-7c003a7b3211"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.3)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n","Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.0)\n","Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n","Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.111.0)\n","Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.30.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n","Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.5.0)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n","Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.18.1)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.0)\n","Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.46b0)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n","Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n","Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n","Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.3)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n","Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (30.1.0)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.4.2)\n","Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n","Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.6)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n","Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n","Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n","Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n","Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n","Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (5.10.0)\n","Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (2.2.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.6.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12.1)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n","Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (7.1.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n","Requirement already satisfied: opentelemetry-proto==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n","Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n","Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n","Requirement already satisfied: opentelemetry-util-http==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n","Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n","Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n","Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.1)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n"]}]},{"cell_type":"code","source":["def create_embeddings_chroma(chunks, persist_directory='./chroma_db'):\n","    from langchain.vectorstores import Chroma\n","    from sentence_transformers import SentenceTransformer\n","\n","    # Define a custom embedding class to integrate with Chroma\n","    class CustomEmbeddings:\n","        def __init__(self, model_name='all-MiniLM-L6-v2'):\n","            self.model = SentenceTransformer(model_name)\n","\n","        def embed(self, texts):\n","            return self.model.encode(texts, convert_to_tensor=False).tolist()\n","\n","        def embed_documents(self, documents):\n","            texts = [doc.page_content for doc in documents]\n","            return self.embed(texts)\n","\n","    embeddings = CustomEmbeddings()\n","\n","    # Create a Chroma vector store using the provided text chunks and embedding model,\n","    # configuring it to save data to the specified directory\n","    vector_store = Chroma.from_documents(chunks, embeddings, persist_directory=persist_directory)\n","\n","    return vector_store  # Return the created vector store\n"],"metadata":{"id":"j420lKGBWlHr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load embeddings\n","def load_embeddings_chroma(persist_directory='./chroma_db'):\n","    from langchain.vectorstores import Chroma\n","    from sentence_transformers import SentenceTransformer\n","\n","    # Define a custom embedding class to integrate with Chroma\n","    class CustomEmbeddings:\n","        def __init__(self, model_name='all-MiniLM-L6-v2'):\n","            self.model = SentenceTransformer(model_name)\n","\n","        def embed(self, texts):\n","            return self.model.encode(texts, convert_to_tensor=False).tolist()\n","\n","        def embed_documents(self, documents):\n","            texts = [doc.page_content for doc in documents]\n","            return self.embed(texts)\n","\n","    embeddings = CustomEmbeddings()\n","\n","    # Create a Chroma vector store using the provided text chunks and embedding model,\n","    # configuring it to save data to the specified directory\n","    vector_store = Chroma.from_documents(chunks, embeddings, persist_directory=persist_directory)\n","\n","    return vector_store  # Return the created vector store\n"],"metadata":{"id":"DnK37InbXYV0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Method 2 working **"],"metadata":{"id":"qqDhg0xTX4w1"}},{"cell_type":"code","source":["import os\n","from pypdf import PdfReader\n","import re\n","import google.generativeai as genai\n","from chromadb import Documents, EmbeddingFunction, Embeddings\n","import chromadb\n","from typing import List\n","\n","# Set and validate the API key for Gemini API\n","os.environ['GEMINI_API_KEY'] = 'AIzaSyBCH44djBwy-dcdIT9HsI8AWrVobma-aiA'\n","gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n","if not gemini_api_key:\n","    raise ValueError(\"Gemini API Key not provided or incorrect. Please provide a valid GEMINI_API_KEY.\")\n","try:\n","    genai.configure(api_key=gemini_api_key)\n","    print(\"API configured successfully with the provided key.\")\n","except Exception as e:\n","    print(\"Failed to configure API:\", str(e))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSCxulhfs1fy","executionInfo":{"status":"ok","timestamp":1720146163750,"user_tz":300,"elapsed":374,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"c7c80367-712b-4e6e-b297-dc45f9da8e7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["API configured successfully with the provided key.\n"]}]},{"cell_type":"code","source":["import os\n","from pypdf import PdfReader\n","import re\n","import google.generativeai as genai\n","from chromadb import Documents, EmbeddingFunction, Embeddings\n","import chromadb\n","from typing import List\n","\n","# Set and validate the API key for Gemini API\n","os.environ['GEMINI_API_KEY'] = 'AIzaSyBCH44djBwy-dcdIT9HsI8AWrVobma-aiA'\n","gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n","if not gemini_api_key:\n","    raise ValueError(\"Gemini API Key not provided or incorrect. Please provide a valid GEMINI_API_KEY.\")\n","try:\n","    genai.configure(api_key=gemini_api_key)\n","    print(\"API configured successfully with the provided key.\")\n","except Exception as e:\n","    print(\"Failed to configure API:\", str(e))\n","\n","# Load the PDF file and extract text from each page\n","def load_pdf(file_path):\n","    reader = PdfReader(file_path)\n","    text = \"\"\n","    for page in reader.pages:\n","        page_text = page.extract_text()\n","        if page_text:\n","            text += page_text\n","    return text\n","\n","# Load your PDF file (replace the path with your actual file path)\n","pdf_path = '/content/drive/MyDrive/LangChain/rag_powered_by_google_search.pdf'\n","pdf_text = load_pdf(pdf_path)\n","\n","# Split the text into smaller chunks based on double newlines\n","def split_text(text, max_chunk_size=500):\n","    chunks = []\n","    current_chunk = \"\"\n","\n","    for paragraph in re.split('\\n\\n', text):\n","        if len(current_chunk) + len(paragraph) <= max_chunk_size:\n","            current_chunk += paragraph + \"\\n\\n\"\n","        else:\n","            chunks.append(current_chunk)\n","            current_chunk = paragraph + \"\\n\\n\"\n","\n","    if current_chunk:\n","        chunks.append(current_chunk)\n","\n","    return [chunk.strip() for chunk in chunks if chunk.strip()]\n","\n","chunked_text = split_text(pdf_text)\n","\n","# Define a custom embedding function using Gemini API\n","class GeminiEmbeddingFunction(EmbeddingFunction):\n","    def __call__(self, input: Documents) -> Embeddings:\n","        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n","        genai.configure(api_key=gemini_api_key)\n","        model = \"models/embedding-001\"\n","        title = \"Custom query\"\n","\n","        embeddings = []\n","        batch_size = 10  # Adjust batch size as needed to fit within the limit\n","\n","        for i in range(0, len(input), batch_size):\n","            batch = input[i:i+batch_size]\n","            response = genai.embed_content(model=model, content=batch, task_type=\"retrieval_document\", title=title)\n","            embeddings.extend(response[\"embedding\"])\n","\n","        return embeddings\n","\n","# Create directory for database if it doesn't exist\n","db_folder = \"chroma_db\"\n","if not os.path.exists(db_folder):\n","    os.makedirs(db_folder)\n","\n","# Function to delete an existing collection\n","def delete_chroma_collection(path: str, name: str):\n","    chroma_client = chromadb.PersistentClient(path=path)\n","    try:\n","        chroma_client.delete_collection(name=name)\n","        print(f\"Collection {name} deleted successfully.\")\n","    except Exception as e:\n","        print(f\"Failed to delete collection {name}: {str(e)}\")\n","\n","# Create a Chroma database with the given documents\n","def create_chroma_db(documents: List[str], path: str, name: str):\n","    chroma_client = chromadb.PersistentClient(path=path)\n","    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n","    for i, d in enumerate(documents):\n","        db.add(documents=[d], ids=[str(i)])\n","    return db, name\n","\n","# Specify the path and collection name for Chroma database\n","db_name = \"rag_experiment\"\n","db_path = os.path.join(os.getcwd(), db_folder)\n","\n","# Delete the existing collection if it exists\n","delete_chroma_collection(db_path, db_name)\n","\n","# Create a new collection\n","db, db_name = create_chroma_db(chunked_text, db_path, db_name)\n","\n","# Load an existing Chroma collection\n","def load_chroma_collection(path: str, name: str):\n","    chroma_client = chromadb.PersistentClient(path=path)\n","    return chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n","\n","db = load_chroma_collection(db_path, db_name)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"IGjq3WrFt_bQ","executionInfo":{"status":"ok","timestamp":1720148015013,"user_tz":300,"elapsed":6241,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"16a3db89-8c15-404b-c1ac-ab61923d9e64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["API configured successfully with the provided key.\n","Collection rag_experiment deleted successfully.\n"]}]},{"cell_type":"code","source":["# Retrieve the most relevant passages based on the query\n","def get_relevant_passage(query: str, db, n_results: int = 3):\n","    results = db.query(query_texts=[query], n_results=n_results)\n","    return [doc[0] for doc in results['documents']]\n","\n","# Construct a prompt for the generation model based on the query and retrieved data\n","def make_rag_prompt(query: str, relevant_passages: List[str]):\n","    escaped_passages = \"\\n\\n\".join([passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \") for passage in relevant_passages])\n","    prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below.\n","Be sure to respond in a complete sentence, being comprehensive, including all relevant background information.\n","However, you are talking to a non-technical audience, so be sure to break down complicated concepts and\n","strike a friendly and conversational tone.\n","QUESTION: '{query}'\n","PASSAGES: '{escaped_passages}'\n","\n","ANSWER:\n","\"\"\"\n","    return prompt\n","\n","# Generate an answer using the Gemini Pro API\n","def generate_answer(prompt: str):\n","    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n","    if not gemini_api_key:\n","        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n","    genai.configure(api_key=gemini_api_key)\n","    model = genai.GenerativeModel('gemini-pro')\n","    result = model.generate_content(prompt)\n","    return result.text\n"],"metadata":{"id":"rGxftcB-xH3a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.memory import ConversationBufferMemory\n","\n","# Initialize conversation buffer memory\n","from langchain.memory import ConversationBufferMemory\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n","\n","# Function to update and use the conversation buffer memory\n","def update_memory_and_generate_answer(query: str, db):\n","    relevant_texts = get_relevant_passage(query, db)\n","    final_prompt = make_rag_prompt(query, relevant_texts)\n","    answer = generate_answer(final_prompt)\n","    memory.save_context({\"input\": query}, {\"output\": answer})\n","    return answer\n","\n","# Function to retrieve chat history\n","def get_chat_history():\n","    return memory.chat_memory.messages\n","\n"],"metadata":{"id":"dPQ6kT4BxK7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_query_and_generate_answer():\n","    while True:\n","        query = input(\"Please enter your query: (type 'exit' to quit) \")\n","        if query.lower() == 'exit':\n","            print(\"Goodbye!\")\n","            break\n","\n","        answer = update_memory_and_generate_answer(query, db)\n","        print(\"Generated Answer:\", answer)\n","        print(\"\\n--- Chat History ---\")\n","        for entry in get_chat_history():\n","            if entry.type == \"human\":\n","                print(f\"User: {entry.content}\")\n","            elif entry.type == \"ai\":\n","                print(f\"Bot: {entry.content}\")\n","            print(\"-------------------\\n\")\n","\n","# Invoke the function to interact with user\n","process_query_and_generate_answer()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7dvlgrLpxRKU","executionInfo":{"status":"ok","timestamp":1720148328686,"user_tz":300,"elapsed":216561,"user":{"displayName":"Ramagiri Poojith","userId":"04026201645389435015"}},"outputId":"1f124307-6a79-4518-d5f3-47ae74f8cd02"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Please enter your query: (type 'exit' to quit) explain rag?\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"]},{"name":"stdout","output_type":"stream","text":["Generated Answer: RAG is an architecture pattern that combines large language models (LLMs) with backend information retrieval from other information sources. This approach can help overcome some of the most significant limitations of LLMs, such as knowledge limited to the scope of training data, lack of relevant context from enterprise data, and data that is not fresh or outdated. It works by using an LLM to generate text, and then using a retrieval system to find relevant information from a database. This can be used to create more informative and engaging content, or to help users find information more easily.\n","\n","--- Chat History ---\n","User: explain rag?\n","-------------------\n","\n","Bot: RAG is an architecture pattern that combines large language models (LLMs) with backend information retrieval from other information sources. This approach can help overcome some of the most significant limitations of LLMs, such as knowledge limited to the scope of training data, lack of relevant context from enterprise data, and data that is not fresh or outdated. It works by using an LLM to generate text, and then using a retrieval system to find relevant information from a database. This can be used to create more informative and engaging content, or to help users find information more easily.\n","-------------------\n","\n","Please enter your query: (type 'exit' to quit) what is there in page 10 of the document explain briefly?\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"]},{"name":"stdout","output_type":"stream","text":["Generated Answer: I am sorry, but the provided document does not contain information about page 10. Therefore, I cannot answer your question.\n","\n","--- Chat History ---\n","User: explain rag?\n","-------------------\n","\n","Bot: RAG is an architecture pattern that combines large language models (LLMs) with backend information retrieval from other information sources. This approach can help overcome some of the most significant limitations of LLMs, such as knowledge limited to the scope of training data, lack of relevant context from enterprise data, and data that is not fresh or outdated. It works by using an LLM to generate text, and then using a retrieval system to find relevant information from a database. This can be used to create more informative and engaging content, or to help users find information more easily.\n","-------------------\n","\n","User: what is there in page 10 of the document explain briefly?\n","-------------------\n","\n","Bot: I am sorry, but the provided document does not contain information about page 10. Therefore, I cannot answer your question.\n","-------------------\n","\n","Please enter your query: (type 'exit' to quit) what is vector search?\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"]},{"name":"stdout","output_type":"stream","text":["Generated Answer: Vector search is a technique that finds similarities between documents based on their semantic meanings rather than their exact keyword matches. This is done by mapping documents into vectors, which are mathematical representations of their content. The vectors are then compared to each other to find the most similar ones. This approach is particularly useful in cases where the query and the documents have different semantics, such as when a user searches for \"warm clothing for winter\" and the system needs to understand that the user is looking for items that provide warmth during cold weather, even though the exact words \"warm clothing for winter\" may not appear in the document.\n","\n","--- Chat History ---\n","User: explain rag?\n","-------------------\n","\n","Bot: RAG is an architecture pattern that combines large language models (LLMs) with backend information retrieval from other information sources. This approach can help overcome some of the most significant limitations of LLMs, such as knowledge limited to the scope of training data, lack of relevant context from enterprise data, and data that is not fresh or outdated. It works by using an LLM to generate text, and then using a retrieval system to find relevant information from a database. This can be used to create more informative and engaging content, or to help users find information more easily.\n","-------------------\n","\n","User: what is there in page 10 of the document explain briefly?\n","-------------------\n","\n","Bot: I am sorry, but the provided document does not contain information about page 10. Therefore, I cannot answer your question.\n","-------------------\n","\n","User: what is vector search?\n","-------------------\n","\n","Bot: Vector search is a technique that finds similarities between documents based on their semantic meanings rather than their exact keyword matches. This is done by mapping documents into vectors, which are mathematical representations of their content. The vectors are then compared to each other to find the most similar ones. This approach is particularly useful in cases where the query and the documents have different semantics, such as when a user searches for \"warm clothing for winter\" and the system needs to understand that the user is looking for items that provide warmth during cold weather, even though the exact words \"warm clothing for winter\" may not appear in the document.\n","-------------------\n","\n","Please enter your query: (type 'exit' to quit) tell me about production grade scemantic search from the document?\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"]},{"name":"stdout","output_type":"stream","text":["Generated Answer: Vertex AI Search can be used to create production-grade semantic search experiences. It uses the same RankBrain and neural matching processes as Google Search to generate query and document embeddings, which are vectors that map semantic relationships. These embeddings enable Google-quality semantic search, which is not just a similarity search but must provide smart recommendations to users. Vertex AI Search can also be combined with LLM reasoning to create advanced RAG systems that can discover a broad array of relevant products that match different requirements and attributes, including type, activity, and style.\n","\n","--- Chat History ---\n","User: explain rag?\n","-------------------\n","\n","Bot: RAG is an architecture pattern that combines large language models (LLMs) with backend information retrieval from other information sources. This approach can help overcome some of the most significant limitations of LLMs, such as knowledge limited to the scope of training data, lack of relevant context from enterprise data, and data that is not fresh or outdated. It works by using an LLM to generate text, and then using a retrieval system to find relevant information from a database. This can be used to create more informative and engaging content, or to help users find information more easily.\n","-------------------\n","\n","User: what is there in page 10 of the document explain briefly?\n","-------------------\n","\n","Bot: I am sorry, but the provided document does not contain information about page 10. Therefore, I cannot answer your question.\n","-------------------\n","\n","User: what is vector search?\n","-------------------\n","\n","Bot: Vector search is a technique that finds similarities between documents based on their semantic meanings rather than their exact keyword matches. This is done by mapping documents into vectors, which are mathematical representations of their content. The vectors are then compared to each other to find the most similar ones. This approach is particularly useful in cases where the query and the documents have different semantics, such as when a user searches for \"warm clothing for winter\" and the system needs to understand that the user is looking for items that provide warmth during cold weather, even though the exact words \"warm clothing for winter\" may not appear in the document.\n","-------------------\n","\n","User: tell me about production grade scemantic search from the document?\n","-------------------\n","\n","Bot: Vertex AI Search can be used to create production-grade semantic search experiences. It uses the same RankBrain and neural matching processes as Google Search to generate query and document embeddings, which are vectors that map semantic relationships. These embeddings enable Google-quality semantic search, which is not just a similarity search but must provide smart recommendations to users. Vertex AI Search can also be combined with LLM reasoning to create advanced RAG systems that can discover a broad array of relevant products that match different requirements and attributes, including type, activity, and style.\n","-------------------\n","\n","Please enter your query: (type 'exit' to quit) quit\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"]},{"output_type":"stream","name":"stdout","text":["Generated Answer: I apologize, but I'm unable to answer this question since the reference passage does not contain any details about the topic 'quit'.\n","\n","--- Chat History ---\n","User: explain rag?\n","-------------------\n","\n","Bot: RAG is an architecture pattern that combines large language models (LLMs) with backend information retrieval from other information sources. This approach can help overcome some of the most significant limitations of LLMs, such as knowledge limited to the scope of training data, lack of relevant context from enterprise data, and data that is not fresh or outdated. It works by using an LLM to generate text, and then using a retrieval system to find relevant information from a database. This can be used to create more informative and engaging content, or to help users find information more easily.\n","-------------------\n","\n","User: what is there in page 10 of the document explain briefly?\n","-------------------\n","\n","Bot: I am sorry, but the provided document does not contain information about page 10. Therefore, I cannot answer your question.\n","-------------------\n","\n","User: what is vector search?\n","-------------------\n","\n","Bot: Vector search is a technique that finds similarities between documents based on their semantic meanings rather than their exact keyword matches. This is done by mapping documents into vectors, which are mathematical representations of their content. The vectors are then compared to each other to find the most similar ones. This approach is particularly useful in cases where the query and the documents have different semantics, such as when a user searches for \"warm clothing for winter\" and the system needs to understand that the user is looking for items that provide warmth during cold weather, even though the exact words \"warm clothing for winter\" may not appear in the document.\n","-------------------\n","\n","User: tell me about production grade scemantic search from the document?\n","-------------------\n","\n","Bot: Vertex AI Search can be used to create production-grade semantic search experiences. It uses the same RankBrain and neural matching processes as Google Search to generate query and document embeddings, which are vectors that map semantic relationships. These embeddings enable Google-quality semantic search, which is not just a similarity search but must provide smart recommendations to users. Vertex AI Search can also be combined with LLM reasoning to create advanced RAG systems that can discover a broad array of relevant products that match different requirements and attributes, including type, activity, and style.\n","-------------------\n","\n","User: quit\n","-------------------\n","\n","Bot: I apologize, but I'm unable to answer this question since the reference passage does not contain any details about the topic 'quit'.\n","-------------------\n","\n","Please enter your query: (type 'exit' to quit) exit\n","Goodbye!\n"]}]}]}